{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PPCES - Task: Regression with California Housing Dataset\n",
    "In this task, participants should apply preprocessing and regression techniques to the California housing (real world) dataset from scikit-learn, which lists several houses, specific attributes of the houses and their prices. The task involves\n",
    "- Loading the dataset\n",
    "- Applying preprocessing techniques such as feature standardization\n",
    "- Training and evaluating the regression model\n",
    "- Visualization results and scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Load desired Python modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import datasets, preprocessing, metrics\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Loading the dataset\n",
    "Load the dataset and print out the following information\n",
    "- Description of the dataset\n",
    "- Array shape of the feature data that is used for training the model\n",
    "- Array shape of the label / target data\n",
    "- List of the feature names\n",
    "- List of the target names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the dataset\n",
    "dataset = datasets.fetch_california_housing()\n",
    "\n",
    "# print desired information\n",
    "print(f\"Data set description:\\n{dataset.DESCR}\")\n",
    "print(f\"Shape of feature / training data: {dataset.data.shape}\")\n",
    "print(f\"Shape of label data: {dataset.target.shape}\")\n",
    "print(f\"Feature names: {dataset.feature_names}\")\n",
    "print(f\"Target names: {dataset.target_names}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Data preprocessing\n",
    "Run the following:\n",
    "- Determine the min, max and avg values per feature\n",
    "  - You should see that the value ranges are quite different per feature\n",
    "  - Some models work better if all features have a similar order of magnitude\n",
    "- Split the data into train and test splits\n",
    "- Apply standardization to the training data split\n",
    "  - Note: of course you also need to apply the same standardization to the test split later!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# determine min and max values per feature\n",
    "min_vals = list(dataset.data.min(axis=0))\n",
    "avg_vals = list(dataset.data.mean(axis=0))\n",
    "max_vals = list(dataset.data.max(axis=0))\n",
    "\n",
    "for i in range(len(min_vals)):\n",
    "    print(f\"{dataset.feature_names[i]:15}:\\tMin\\t{min_vals[i]:8.3f}\\tAvg\\t{avg_vals[i]:8.3f}\\tMax\\t{max_vals[i]:8.3f}\")\n",
    "\n",
    "# split data into train and test split (Use 20% test data)\n",
    "X_train, X_test, y_train, y_test = train_test_split(dataset.data, dataset.target, test_size=0.20, random_state=42, shuffle=True)\n",
    "\n",
    "# create a StandardScaler\n",
    "scaler = preprocessing.StandardScaler()\n",
    "\n",
    "# scale training data\n",
    "scaler = scaler.fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "print(f\"Scaler mean values (based on training set):\\n{scaler.mean_}\")\n",
    "print(f\"Scaler scale values (based on training set):\\n{scaler.scale_}\")\n",
    "\n",
    "# dont forget to apply the same scaler to the test data split\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Train a Support Vector Regression (SVR) or RandomForest Regression model\n",
    "For SVR, use the following parameters:\n",
    "- `C=1.0` (regularization parameter)\n",
    "- `epsilon=0.2` (specifies the epsilon-tube within which no penalty is associated in the training loss function with points predicted within a distance epsilon from the actual value)\n",
    "\n",
    "For RandomForest, use the following parameters:\n",
    "- `n_estimators=10` (Number of different trees)\n",
    "- `random_state=42`\n",
    "- `max_depth=None` (depth of the trees, `None` will figure it out on its own)\n",
    "- You can also play around with number of trees and depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create and intialize the model\n",
    "model = SVR(C=1.0, epsilon=0.2)\n",
    "# model = RandomForestRegressor(n_estimators=10, max_depth=None, random_state=42)\n",
    "\n",
    "# train / fit the model\n",
    "elapsed_time = time.time()\n",
    "model = model.fit(X_train, y_train)\n",
    "elapsed_time = time.time() - elapsed_time\n",
    "\n",
    "print(f\"Elapsed time for training: {elapsed_time} sec\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Evaluate the model using typical scoring functions\n",
    "To evaluate the model performance, do the following:\n",
    "- Predict the housing prices for the test split with the trained model (applying on unseen data)\n",
    "- Plot both original (ground truth) and predicted values\n",
    "- Determine `r2_score`, `mean_absolute_error` and `mean_absolute_percentage_error` for the prediction\n",
    "  - Note: There are multiple scoring functions for different purposes. You can find more information here: https://scikit-learn.org/stable/modules/model_evaluation.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict housing prices for test split\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Plot both original (ground truth) and predicted values. Limited to the first 100 values to see differences \n",
    "plt.figure()\n",
    "plt.plot(y_test[:100]*100_000, color=\"blue\", label=\"ground truth\")\n",
    "plt.plot(y_pred[:100]*100_000, color=\"red\", label=\"predicted\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"House\")\n",
    "plt.ylabel(\"Price in USD\")\n",
    "plt.show()\n",
    "\n",
    "# determine r2 and mean_absolute_error\n",
    "val_r2  = metrics.r2_score(y_test, y_pred)\n",
    "val_mae = metrics.mean_absolute_error(y_test, y_pred)\n",
    "val_mape = metrics.mean_absolute_percentage_error(y_test, y_pred)\n",
    "\n",
    "# print results\n",
    "print(f\"R2: {val_r2}\")\n",
    "print(f\"MAE: {val_mae*100_000} whereas mean house prices are {y_test.mean()*100_000}\")\n",
    "print(f\"MAPE: {val_mape}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jupyter",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
